{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraries and defining the Net class (same class with which the networks were generated)\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Any, Callable, Optional, Tuple\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import quadprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "k880Ih2e3PBf"
   },
   "outputs": [],
   "source": [
    "# Network class\n",
    "k=1\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        self.layers+=[nn.Sequential(nn.Conv2d(3, 16*k,  kernel_size=3) , nn.BatchNorm2d(16*k),\n",
    "                      nn.ReLU(inplace=True)), nn.Sequential(nn.Conv2d(16*k, 16*k,  kernel_size=3) , nn.BatchNorm2d(16*k),\n",
    "                      nn.ReLU(inplace=True))] \n",
    "        self.layers+=[nn.Sequential(nn.Conv2d(16*k, 32*k,  kernel_size=3, stride=2),  nn.BatchNorm2d(32*k),\n",
    "                      nn.ReLU(inplace=True))]\n",
    "        self.layers+=[nn.Sequential(nn.Conv2d(32*k, 32*k,  kernel_size=3),  nn.BatchNorm2d(32*k),\n",
    "              nn.ReLU(inplace=True)),nn.Sequential(nn.Conv2d(32*k, 32*k,  kernel_size=3),  nn.BatchNorm2d(32*k),\n",
    "              nn.ReLU(inplace=True))]\n",
    "        self.layers+=[nn.Sequential(nn.Conv2d(32*k, 64*k,  kernel_size=3, stride=2), nn.BatchNorm2d(64*k),\n",
    "                      nn.ReLU(inplace=True))]\n",
    "        self.layers+=[nn.Sequential(nn.Conv2d(64*k, 64*k,  kernel_size=3, padding='valid'), nn.BatchNorm2d(64*k),\n",
    "                      nn.ReLU(inplace=True))]\n",
    "        self.layers+=[nn.Sequential(nn.Conv2d(64*k, 64*k,  kernel_size=1), nn.BatchNorm2d(64*k),\n",
    "                      nn.ReLU(inplace=True))]\n",
    "        self.layers+= [nn.AdaptiveAvgPool2d((1,1))]\n",
    "        self.fc = nn.Linear(64*k, 10)\n",
    "    \n",
    "    def forward(self, x, acts_only=False,all_act=False):\n",
    "        all_acts = []\n",
    "        for i in range(len(self.layers[:-1])):\n",
    "#             all_acts.append(x)\n",
    "            x = self.layers[i](x)\n",
    "            all_acts.append(x)\n",
    "        \n",
    "        x = self.layers[-1](x) #Had to add this since it's not in the loop anymore\n",
    "        x = self.fc(x.view(-1, 64*k))\n",
    "\n",
    "        if all_act:\n",
    "            # all_cts does not return the final output of the network\n",
    "            return all_acts, x\n",
    "        return x\n",
    "    \n",
    "    def forward_embed(self, x, layer_idx = -1):\n",
    "#         print(len(self.layers[:layer_idx]))\n",
    "        for i in range(len(self.layers[:layer_idx])):\n",
    "             x = self.layers[i](x)\n",
    "                \n",
    "        return x\n",
    "    \n",
    "# Defining linear CKA\n",
    "class LinCKA(nn.Module):\n",
    "    def __init__(self, n=1000):\n",
    "        super(LinCKA, self).__init__()\n",
    "        self.resetK(n)\n",
    "    \n",
    "    def resetK(self,n):\n",
    "        unit = torch.ones([n, n])\n",
    "        I = torch.eye(n)\n",
    "        H = I - unit / n\n",
    "        H = H.cuda()\n",
    "        self.H = H.cuda()\n",
    "        self.n = n\n",
    "\n",
    "    def centering(self, K):\n",
    "        H = self.H\n",
    "        return torch.matmul(torch.matmul(H, K), H) \n",
    "\n",
    "    def linear_HSIC(self, X, Y):\n",
    "        L_X = torch.matmul(X, X.T)\n",
    "        L_Y = torch.matmul(Y, Y.T)\n",
    "        return torch.sum(self.centering(L_X) * self.centering(L_Y))\n",
    "\n",
    "    def linear_CKA(self,X, Y):\n",
    "        hsic = self.linear_HSIC(X, Y)\n",
    "        var1 = torch.sqrt(self.linear_HSIC(X, X))\n",
    "        var2 = torch.sqrt(self.linear_HSIC(Y, Y))\n",
    "\n",
    "        return hsic / (var1 * var2),var1,var2\n",
    "\n",
    "    def forward(self, X,Y):\n",
    "        if len(X) != self.n:\n",
    "            self.resetK(len(X))\n",
    "        return self.linear_CKA(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxrHSBk_Yhrq",
    "outputId": "45088feb-7b91-4ec4-e3e1-348e8228f309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=valid)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the saved networks\n",
    "PATH='net_kornblith/net_kornblith_'\n",
    "\n",
    "net_all1 = Net()\n",
    "net_all1.load_state_dict(torch.load(PATH+'all_1.zip'))\n",
    "net_all1.eval()\n",
    "net_all1.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split and train experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations_by_class(data, labels):\n",
    "    indexes = []\n",
    "    datapoints = []\n",
    "    \n",
    "    for label in range(10): #for label in set(labels): \n",
    "        indexes.append(np.where(labels==label))\n",
    "        datapoints.append(data[indexes[-1]])\n",
    "    \n",
    "    return datapoints, np.array(indexes).squeeze()\n",
    "\n",
    "def split_class_clusters(data, indexes, d, W, n_clusters, split_constant, ortho_d = True, experiment = 'one_class_one_point'):\n",
    "    # data should be of shape n x d (n examples, d features)\n",
    "    # d is the random direction vector\n",
    "    # W comes from lin_svc.coef_ (n_classes, n_features) corresponding to the normal vectors to the decision hyperplanes\n",
    "    data_ = np.copy(data)\n",
    "    \n",
    "    if ortho_d:\n",
    "        Q, R = np.linalg.qr(W.T)\n",
    "        d_ = d.reshape([1,np.max(d.shape)])\n",
    "        d_ -= np.matmul(d_, np.matmul(Q, Q.T))\n",
    "#     print(\"Direction after removing components: {}\".format(d_))\n",
    "    else:\n",
    "        d_ = d\n",
    "    \n",
    "    projections = np.matmul(data_, d_.T).squeeze()\n",
    "    mean = np.mean(projections)\n",
    "    min_ = np.min(projections)\n",
    "    max_ = np.max(projections)\n",
    "    \n",
    "    translations = np.zeros(data_.shape[0])\n",
    "    \n",
    "    idxs = []\n",
    "    separators = np.linspace(min_,max_,n_clusters+1)\n",
    "    if 'one_point' in experiment: \n",
    "        if n_clusters != 2:\n",
    "            print(\"ERROR: one point experiment won't work because number of clusters is not 2\")\n",
    "        else:\n",
    "            separators = np.linspace(min_,max_,n_clusters)\n",
    "        \n",
    "    for cluster_idx in range(n_clusters):\n",
    "        idx = np.where(projections>=separators[cluster_idx])\n",
    "        if cluster_idx < (n_clusters-1): # Except for last cluster we need to take into account that the projections are not superior to the next separator\n",
    "            idx2 = idx2 = np.where(projections<separators[cluster_idx+1])\n",
    "            idx = np.intersect1d(idx, idx2)\n",
    "        idxs.append(idx)\n",
    "        translations[idxs[-1]] = cluster_idx*split_constant \n",
    "#     print(\"Translations before mult: {}\".format(translations))\n",
    "    \n",
    "    translations = np.matmul(np.diag(translations.squeeze()), np.matmul(np.ones([data_.shape[0],1]), d_))\n",
    "#     print(\"Translations after mult: {}\".format(translations))\n",
    "    \n",
    "    data_+= translations\n",
    "    return data_, np.array([indexes[i] for i in idxs]).squeeze()\n",
    "\n",
    "def test_cka_lin_sep(data_per_classes, indexes, lin_svc,\n",
    "                     num_clusters = 2,\n",
    "                     dist_clusters = 100,\n",
    "                     splitting_dir='pc4',\n",
    "                     num_pts_cka = 10000,\n",
    "                     seed = 0,\n",
    "                     experiment = \"one_class_one_point\"):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    print('Number of clusters: {}; Distance between clusters: {}; Splitting direction: '.format(num_clusters, dist_clusters)+splitting_dir+'; Number of points to compute CKA: {}'.format(num_pts_cka))\n",
    "    \n",
    "    labels = np.zeros(len(data_per_classes[0]))\n",
    "    split_data = []\n",
    "    split_indexes = []\n",
    "    \n",
    "    if splitting_dir == 'num_solve':\n",
    "        print('Numerically find a distance for all classes')\n",
    "        \n",
    "        dim = data_per_classes[0].shape[1]\n",
    "        Q, R = np.linalg.qr(lin_svc.coef_.T)\n",
    "            \n",
    "        M = Q.T\n",
    "        # P = np.dot(M.T, M) # Not positive definite\n",
    "        epsilon = 1e-7\n",
    "        P = np.dot(M.T, M) + epsilon*np.eye(M.shape[1]) # Adding epsilon * identity to make it positive definite\n",
    "        q = -np.dot(M.T, np.zeros(10))\n",
    "        G = -np.eye(dim)\n",
    "        # h = np.zeros(256) # returns all zeros\n",
    "        h =  -np.ones(dim)*0.1\n",
    "            \n",
    "        direction = quadprog_solve_qp(P, q, G, h)\n",
    "        norm = np.sum(direction**2)**(0.5)\n",
    "        direction = direction/norm\n",
    "    \n",
    "    # Iterate the splitting for each class\n",
    "    for class_idx, class_data in enumerate(data_per_classes):\n",
    "        \n",
    "        # Define the direction along which to split the data\n",
    "        if 'pc' in splitting_dir:\n",
    "            direction = PCA(n_components = int(splitting_dir[2:])).fit(class_data).components_[int(splitting_dir[2:])-1]\n",
    "        if splitting_dir == 'random':\n",
    "#             # Sample from un-centered cube (not to be used)\n",
    "#             direction = np.random.rand(1, class_data.shape[1])\n",
    "#             # Sample from sphere using cubes (takes way to much time)\n",
    "#             while np.linalg.norm(direction)> 1:\n",
    "#                 direction = np.random.rand(1, class_data.shape[1])\n",
    "#                 direction = direction/np.linalg.norm(direction)\n",
    "            direction = np.random.normal(0, 1, class_data.shape[1])\n",
    "            norm = np.sum(direction**2)**(0.5)\n",
    "            direction = direction/norm\n",
    "            direction = np.absolute(direction)\n",
    "#             print(\"Direction: {}\".format(direction))\n",
    "        \n",
    "        # Split the data\n",
    "        if 'one_class' in experiment:\n",
    "            if class_idx > 0: dist_clusters = 0\n",
    "                \n",
    "        splits = split_class_clusters(class_data, indexes[class_idx], direction, lin_svc.coef_, num_clusters, dist_clusters, experiment = experiment)\n",
    "        split_data.append(splits[0])\n",
    "        split_indexes.append([i for i in splits[1]])\n",
    "        if class_idx != 0: labels = np.concatenate([labels, class_idx*np.ones(split_data[-1].shape[0])])\n",
    "        \n",
    "    split_data = np.concatenate(split_data)\n",
    "    original_data = torch.Tensor(np.concatenate(data_per_classes)).cuda()\n",
    "    \n",
    "    lin_sep = lin_svc.score(split_data, labels)\n",
    "    print(\"Accuracy of the linear SVM classifier on the split data: {}\".format(lin_sep))\n",
    "    \n",
    "    split_data = torch.Tensor(split_data).cuda()\n",
    "    # CKA values\n",
    "    CKA = LinCKA()\n",
    "    perm = np.random.permutation(num_pts_cka)\n",
    "    cka = CKA(original_data[perm], split_data[perm])[0].item()\n",
    "    print(\"Cka between {} original vs split pts: {}\".format(num_pts_cka, cka))\n",
    "    return lin_sep, cka, split_data.cpu().numpy(), np.concatenate(indexes), split_indexes\n",
    "\n",
    "def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    qp_G = .5 * (P + P.T)   # make sure P is symmetric\n",
    "    qp_a = -q\n",
    "    if A is not None:\n",
    "        qp_C = -numpy.vstack([A, G]).T\n",
    "        qp_b = -numpy.hstack([b, h])\n",
    "        meq = A.shape[0]\n",
    "    else:  # no equality constraint\n",
    "        qp_C = -G.T\n",
    "        qp_b = -h\n",
    "        meq = 0\n",
    "    return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save the data (only run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10_mod(datasets.CIFAR10):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        a = super().__getitem__(index)\n",
    "        return (a[0], a[1], index, torch.zeros(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "##### Loading CIFAR10 data\n",
    "cifar_data = CIFAR10_mod(root='.',train=True, transform=transform, download=True)\n",
    "\n",
    "#### Creading data loaders\n",
    "train_loaderx = torch.utils.data.DataLoader(cifar_data, batch_size=50000, shuffle=False)\n",
    "\n",
    "train_data, train_labels, train_indexes, train_embeds = iter(train_loaderx).next()\n",
    "train_data = train_data.to(device)\n",
    "train_labels = train_labels.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of a linear SVM classifier on the original data: 0.88326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "layer_idx = -3\n",
    "\n",
    "train_activations, _ = net_all1.forward(train_data, all_act=True)\n",
    "train_act = train_activations[layer_idx].reshape(train_activations[layer_idx].shape[0],-1).detach().cpu().numpy()\n",
    "train_act_tensors = train_activations[layer_idx]\n",
    "del train_activations\n",
    "\n",
    "# Linear separability:\n",
    "lin_svc = LinearSVC()\n",
    "lin_svc.fit(train_act, train_labels)\n",
    "original_lin_sep = lin_svc.score(train_act, train_labels)\n",
    "print(\"Accuracy of a linear SVM classifier on the original data: {}\".format(original_lin_sep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2; Distance between clusters: 1000; Splitting direction: num_solve; Number of points to compute CKA: 10000\n",
      "Numerically find a distance for all classes\n",
      "Accuracy of the linear SVM classifier on the split data: 0.88326\n",
      "Cka between 10000 original vs split pts: 0.10027597099542618\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 2\n",
    "dist_clusters = 1000\n",
    "splitting_dir = 'num_solve'\n",
    "num_pts_cka = 10000\n",
    "seed = 0\n",
    "experiment = '' # '' or '_one_class' or '_one_class_one_point'\n",
    "\n",
    "data_per_classes, indexes = get_activations_by_class(train_act, train_labels)\n",
    "lin_sep, cka, split_embeds, indexes, split_indexes = test_cka_lin_sep(data_per_classes, indexes, lin_svc, num_clusters = num_clusters, dist_clusters = dist_clusters, splitting_dir = splitting_dir, num_pts_cka = num_pts_cka, seed = seed, experiment = experiment)\n",
    "\n",
    "if layer_idx == -1 or layer_idx == -2:\n",
    "    sorted_split_embeds = torch.Tensor(split_embeds[np.argsort(indexes)]).reshape([50000, 64, 2, 2])\n",
    "elif layer_idx == -3:\n",
    "    sorted_split_embeds = torch.Tensor(split_embeds[np.argsort(indexes)]).reshape([50000, 64, 4, 4])\n",
    "elif layer_idx == -4:\n",
    "    sorted_split_embeds = torch.Tensor(split_embeds[np.argsort(indexes)]).reshape([50000, 32, 9, 9])\n",
    "elif layer_idx == -5:\n",
    "    sorted_split_embeds = torch.Tensor(split_embeds[np.argsort(indexes)]).reshape([50000, 32, 11, 11])\n",
    "torch.save(sorted_split_embeds, 'data/cifar10_sorted_split_layer{}_embeds_{}num-clusters_{}dist-clusters_'.format(layer_idx, num_clusters, dist_clusters)+splitting_dir+'_{}pts-cka_{}seed'.format(num_pts_cka,seed)+experiment+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_act, data_per_classes, indexes, split_embeds, split_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check size of each layer's output (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 64, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tr\n",
    "tr = net_all1.forward_embed(train_data, layer_idx = -1)\n",
    "tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ef72b7584c66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "del tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_activations, _ = net_all1.forward(train_data, all_act=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_activations = net_all1.forward_embed(train_data, layer_idx=-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 32, 11, 11])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_activations[-5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(train_activations[0]-train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2a56fdd7c30e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Tensor' is not defined"
     ]
    }
   ],
   "source": [
    "Tensor(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small test to check positiveness of values (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(sorted_split_embeds.numpy())\n",
    "# all the activations are positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1002.9497  1003.11597 1002.8482  ... 1002.6757  1002.90466 1002.63196]\n"
     ]
    }
   ],
   "source": [
    "norms = np.array([np.linalg.norm(sorted_split_embeds[i]) for i in range(50000)])\n",
    "print(norms[np.where(norms>50)])\n",
    "# There is only one point significantly far from the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = -3\n",
    "\n",
    "num_clusters = 2\n",
    "dist_clusters = 1000\n",
    "splitting_dir = 'num_solve'\n",
    "num_pts_cka = 10000\n",
    "seed = 0\n",
    "experiment = '' # '' or '_one_class_one_point' or '_one_class'\n",
    "\n",
    "#old_file = 'data/cifar10_sorted_split_last_layer_embeds_{}num-clusters_{}dist-clusters_'.format(num_clusters, dist_clusters)+splitting_dir+'_{}pts-cka_{}seed.pt'.format(num_pts_cka,seed)\n",
    "file_path = 'data/cifar10_sorted_split_layer{}_embeds_{}num-clusters_{}dist-clusters_'.format(layer_idx, num_clusters, dist_clusters)+splitting_dir+'_{}pts-cka_{}seed'.format(num_pts_cka,seed)+experiment+'.pt'\n",
    "\n",
    "class CIFAR10_mod(datasets.CIFAR10):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "        self.split_embeds = torch.load(file_path)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        a = super().__getitem__(index)\n",
    "        return (a[0], a[1], index, self.split_embeds[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Import data \n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), normalize,])\n",
    "\n",
    "##### Loading CIFAR10 data\n",
    "cifar_data = CIFAR10_mod(root='.' ,train=True, transform=transform, download=True)\n",
    "cifar_data_test = datasets.CIFAR10(root='.' ,train=False, transform=transform, download=True)\n",
    "\n",
    "#### Creading data loaders\n",
    "train_loaderx = torch.utils.data.DataLoader(cifar_data, batch_size=2048, shuffle=False)\n",
    "test_loaderx = torch.utils.data.DataLoader(cifar_data_test, batch_size=10000, shuffle=False)\n",
    "\n",
    "# train_data, train_labels, train_indexes, train_embeds = iter(train_loaderx).next()\n",
    "# train_data = train_data.to(device)\n",
    "# train_labels = train_labels.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss(model, data_loader, loss_fct, layer_idx = -1):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, label, index, split_embed) in enumerate(data_loader):\n",
    "            data, split_embed = data.to(device), split_embed.to(device)\n",
    "            output = model.forward_embed(data, layer_idx = layer_idx)\n",
    "#             print(output.shape)\n",
    "#             print(split_embed.shape)\n",
    "            eval_loss += loss_fct(output, split_embed).detach()\n",
    "    return eval_loss\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "def train_embeds(model, device, train_loader, loss_fct = F.mse_loss, optimizer = torch.optim.Adam, epoch = 0, lr=0.1, layer_idx = -1, display=True):    \n",
    "    # Evaluating the loss on the whole dataset before starting training\n",
    "    before_training_loss = evaluate_loss(model, train_loader, loss_fct, layer_idx=layer_idx)\n",
    "    \n",
    "    # Training the model\n",
    "    model.train()\n",
    "    \n",
    "    ## Setting which layers to train and defining the optimizer\n",
    "    for name, param in model.named_parameters():\n",
    "        if (\"layers\" in name):\n",
    "            if int(name.split('.')[1])<(9+layer_idx):\n",
    "                param.requires_grad = True\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "    optimizer = optimizer(model.parameters(), lr = lr)\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, label, index, split_embed) in enumerate(train_loader):\n",
    "        data, split_embed = data.to(device), split_embed.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward_embed(data, layer_idx = layer_idx)\n",
    "        loss = loss_fct(output, split_embed)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    after_training_loss = evaluate_loss(model, train_loader, loss_fct, layer_idx = layer_idx)\n",
    "    \n",
    "    if display:\n",
    "        print('Epoch {} - Before training loss: {} | After training loss: {}'.format(epoch, before_training_loss, after_training_loss))\n",
    "    \n",
    "    return before_training_loss, after_training_loss\n",
    "    \n",
    "# Would need an option to train starting at a certain layer up to a certain layer (where the embedings were split)\n",
    "# => did it, should work now\n",
    "    \n",
    "def train_fc_layer(model, device, train_loader, loss_fct = F.cross_entropy, optimizer = torch.optim.Adam,  lr=0.1, display=True):\n",
    "    model.train()\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"layers\" in name:\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            param.requires_grad = True\n",
    "    optimizer = optimizer(model.parameters(), lr = lr)\n",
    "    for batch_idx, (data, label, index, split_embed) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fct(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if display:\n",
    "          print('Train Epoch: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "          batch_idx * len(data), len(train_loader.dataset),\n",
    "          100. * batch_idx / len(train_loader), loss.item()))\n",
    "    \n",
    "def train_classif(model, device, train_loader, loss_fct = F.cross_entropy, optimizer = torch.optim.Adam,  lr=0.1, layer_idx = -1, display=True):\n",
    "    model.train()\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if (\"layers\" in name):\n",
    "            if int(name.split('.')[1])<(9+layer_idx):\n",
    "                param.requires_grad = False\n",
    "            else:\n",
    "                param.requires_grad = True\n",
    "                \n",
    "    optimizer = optimizer(model.parameters(), lr = lr)\n",
    "    \n",
    "    for batch_idx, (data, label, index, split_embed) in enumerate(train_loader):\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = F.one_hot(label, num_classes=10).type(torch.cuda.FloatTensor)\n",
    "        loss = loss_fct(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if display:\n",
    "          print('Train Epoch: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "          batch_idx * len(data), len(train_loader.dataset),\n",
    "          100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tests (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just some tests on this\n",
    "\n",
    "# layer_idx=-1\n",
    "for name, param in net_all1.named_parameters():\n",
    "    print(name)\n",
    "#     if (\"layers\" in name):\n",
    "#         if int(name.split('.')[1])<(9+layer_idx):\n",
    "#             print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hparam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_path)\n",
    "\n",
    "for loss_fct, loss_name in zip([F.mse_loss, nn.L1Loss()], ['MSE', 'L1']):\n",
    "    for optim, optim_name in zip([torch.optim.Adam, torch.optim.SGD],['Adam', 'SGD']):\n",
    "        for lr in [10, 1, 0.1, 0.01, 0.001]:\n",
    "            net = Net()\n",
    "            net.load_state_dict(torch.load('net_kornblith/net_kornblith_all_1.zip'))\n",
    "            net.cuda()\n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr))\n",
    "            for i in range(50):\n",
    "                a, b = train_embeds(net, device, train_loaderx, loss_fct = loss_fct, optimizer = optim, lr = lr, epoch = i, layer_idx = layer_idx, display=True)\n",
    "                if i == 0: initial_loss = a\n",
    "                if i == 24: final_loss = b\n",
    "            del net\n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr)+' - Final / Initial loss %: {}'.format(final_loss/initial_loss*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training one for a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST: Loss: MSE | Optimizer: SGD | Lr: 0.1 - Final / Initial loss %: 66.11437225341797\n",
    "\n",
    "epochs = 600\n",
    "\n",
    "print(file_path)\n",
    "\n",
    "for loss_fct, loss_name in zip([F.mse_loss], ['MSE']):\n",
    "    for optim, optim_name in zip([torch.optim.SGD],['SGD']):\n",
    "        for lr in [0.1]:\n",
    "            net = Net()\n",
    "            net.load_state_dict(torch.load('net_kornblith/net_kornblith_all_1.zip'))\n",
    "            net.cuda()\n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr))\n",
    "            for i in range(epochs):\n",
    "                a, b = train_embeds(net, device, train_loaderx, loss_fct = loss_fct, optimizer = optim, lr = lr, epoch = i, layer_idx = layer_idx, display=True)\n",
    "                if i%25 == 0:\n",
    "                    torch.save(net.state_dict(), 'net_kornblith/split_nets/net_kall1_split_layer{}_train'.format(layer_idx)+experiment+'_mse_sgd_lr0.1_{}e.t7'.format(i))\n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr))#+' - Final / Initial loss %: {}'.format(final_loss/initial_loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'net_kornblith/split_nets/net_kall1_split_layer{}_train'.format(layer_idx)+experiment+'_mse_sgd_lr0.1_{}e.t7'.format(600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST: Loss: MSE | Optimizer: SGD | Lr: 0.1 - Final / Initial loss %: 66.11437225341797\n",
    "\n",
    "epochs = 800\n",
    "\n",
    "print(file_path)\n",
    "\n",
    "for loss_fct, loss_name in zip([F.cross_entropy], ['Cross Entropy']):\n",
    "    for optim, optim_name in zip([torch.optim.Adam],['ADAM']):\n",
    "        for lr in [0.1]:\n",
    "            net = Net()\n",
    "            net.load_state_dict(torch.load('net_kornblith/split_nets/net_kall1_split_layer{}'.format(layer_idx)+'_train_mse_sgd_lr0.1_575e.t7'))\n",
    "            net.cuda()\n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr))\n",
    "            for i in range(epochs):\n",
    "                train_classif(net, device, train_loaderx, loss_fct = loss_fct, optimizer = optim, lr = lr, layer_idx=layer_idx,  display=True)\n",
    "                if i%10 == 0: test(net, torch.device('cuda'), test_loaderx)\n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr))#+' - Final / Initial loss %: {}'.format(final_loss/initial_loss*100))\n",
    "    \n",
    "# torch.save(net.state_dict(), 'net_kornblith/net_kall1_split_train'+experiment+'_mse_sgd_lr0.1_{}e.t7'.format(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training one for a long time with fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/cifar10_sorted_split_layer-3_embeds_2num-clusters_1000dist-clusters_num_solve_10000pts-cka_0seed.pt\n",
      "Loss: MSE | Optimizer: SGD | Lr: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: Using a target size (torch.Size([2048, 64, 4, 4])) that is different to the input size (torch.Size([2048, 64, 2, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-edec3773e217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' | Optimizer: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0moptim_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' | Lr: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_embeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loaderx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m#                 if i == 0: initial_loss = a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#                 if i == 499: final_loss = b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-232d42f7a856>\u001b[0m in \u001b[0;36mtrain_embeds\u001b[0;34m(model, device, train_loader, loss_fct, optimizer, epoch, lr, layer_idx, display)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_embeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Evaluating the loss on the whole dataset before starting training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mbefore_training_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-232d42f7a856>\u001b[0m in \u001b[0;36mevaluate_loss\u001b[0;34m(model, data_loader, loss_fct)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_embed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0meval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_embed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0meval_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main_env/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/main_env/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# BEST: Loss: MSE | Optimizer: SGD | Lr: 0.1 - Final / Initial loss %: 66.11437225341797\n",
    "\n",
    "epochs = 800\n",
    "fc_epochs = 5\n",
    "\n",
    "print(file_path)\n",
    "\n",
    "for loss_fct, loss_name in zip([F.mse_loss], ['MSE']):\n",
    "    for optim, optim_name in zip([torch.optim.SGD],['SGD']):\n",
    "        for lr in [0.1]:\n",
    "            net = Net()\n",
    "            net.load_state_dict(torch.load('net_kornblith/net_kornblith_all_1.zip'))\n",
    "            net.cuda()\n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr))\n",
    "            for i in range(epochs):\n",
    "                a, b = train_embeds(net, device, train_loaderx, loss_fct = loss_fct, optimizer = optim, lr = lr, epoch = i, layer_idx = layer_idx, display=True)\n",
    "#                 if i == 0: initial_loss = a\n",
    "#                 if i == 499: final_loss = b\n",
    "                if i%fc_epochs==0:\n",
    "                    for j in [0,1,2,3,4]:\n",
    "                        train_classif(net, device, train_loaderx, loss_fct = F.cross_entropy, optimizer = optim, lr = 0.01,  layer_idx = layer_idx, display=False)\n",
    "                    test(net, torch.device('cuda'), test_loaderx)\n",
    "                    \n",
    "            print('Loss: '+loss_name+' | Optimizer: '+optim_name+' | Lr: {}'.format(lr))#+' - Final / Initial loss %: {}'.format(final_loss/initial_loss*100))\n",
    "    \n",
    "torch.save(net.state_dict(), 'net_kornblith/net_kall1_split_layer{}_train_fc{}_lr0.01'.format(layer_idx, fc_epochs)+experiment+'_mse_sgd_lr0.1_{}e.t7'.format(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "Test set: Average loss: 0.4737, Accuracy: 8509/10000 (85.09%)\n",
      "\n",
      "New:\n",
      "\n",
      "Test set: Average loss: 12.2197, Accuracy: 1627/10000 (16.27%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16.27"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load('net_kornblith/net_kornblith_all_1.zip'))\n",
    "net.cuda()\n",
    "print('Original:')\n",
    "test(net, torch.device('cuda'), test_loaderx)\n",
    "\n",
    "net2 = Net()\n",
    "net2.load_state_dict(torch.load('net_kornblith/net_kall1_split_train_mse_sgd_lr0.1_500e.t7'))\n",
    "net2.cuda()\n",
    "print('New:')\n",
    "test(net2, torch.device('cuda'), test_loaderx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple training tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w,x,y,z in train_loaderx:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<function mse_loss at 0x7f6ee04f7440>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(F.mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: [20352/50000 (96%)]\tLoss: 94.504486\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 30.571859\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 68.288193\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 70.667366\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 64.377548\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 56.695179\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 62.306759\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 66.344521\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 60.358624\n",
      "Train Epoch: [20352/50000 (96%)]\tLoss: 38.516537\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train_fc_layer(net_all1, device, train_loaderx, lr = 1, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight\n",
      "layers.0.0.bias\n",
      "layers.0.1.weight\n",
      "layers.0.1.bias\n",
      "layers.1.0.weight\n",
      "layers.1.0.bias\n",
      "layers.1.1.weight\n",
      "layers.1.1.bias\n",
      "layers.2.0.weight\n",
      "layers.2.0.bias\n",
      "layers.2.1.weight\n",
      "layers.2.1.bias\n",
      "layers.3.0.weight\n",
      "layers.3.0.bias\n",
      "layers.3.1.weight\n",
      "layers.3.1.bias\n",
      "layers.4.0.weight\n",
      "layers.4.0.bias\n",
      "layers.4.1.weight\n",
      "layers.4.1.bias\n",
      "layers.5.0.weight\n",
      "layers.5.0.bias\n",
      "layers.5.1.weight\n",
      "layers.5.1.bias\n",
      "layers.6.0.weight\n",
      "layers.6.0.bias\n",
      "layers.6.1.weight\n",
      "layers.6.1.bias\n",
      "layers.7.0.weight\n",
      "layers.7.0.bias\n",
      "layers.7.1.weight\n",
      "layers.7.1.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in net_all1.named_parameters():\n",
    "    print(name)\n",
    "#     print(param.requires_grad)\n",
    "    if \"layers\" in name:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight\n",
      "False\n",
      "layers.0.0.bias\n",
      "False\n",
      "layers.0.1.weight\n",
      "False\n",
      "layers.0.1.bias\n",
      "False\n",
      "layers.1.0.weight\n",
      "False\n",
      "layers.1.0.bias\n",
      "False\n",
      "layers.1.1.weight\n",
      "False\n",
      "layers.1.1.bias\n",
      "False\n",
      "layers.2.0.weight\n",
      "False\n",
      "layers.2.0.bias\n",
      "False\n",
      "layers.2.1.weight\n",
      "False\n",
      "layers.2.1.bias\n",
      "False\n",
      "layers.3.0.weight\n",
      "False\n",
      "layers.3.0.bias\n",
      "False\n",
      "layers.3.1.weight\n",
      "False\n",
      "layers.3.1.bias\n",
      "False\n",
      "layers.4.0.weight\n",
      "False\n",
      "layers.4.0.bias\n",
      "False\n",
      "layers.4.1.weight\n",
      "False\n",
      "layers.4.1.bias\n",
      "False\n",
      "layers.5.0.weight\n",
      "False\n",
      "layers.5.0.bias\n",
      "False\n",
      "layers.5.1.weight\n",
      "False\n",
      "layers.5.1.bias\n",
      "False\n",
      "layers.6.0.weight\n",
      "False\n",
      "layers.6.0.bias\n",
      "False\n",
      "layers.6.1.weight\n",
      "False\n",
      "layers.6.1.bias\n",
      "False\n",
      "layers.7.0.weight\n",
      "False\n",
      "layers.7.0.bias\n",
      "False\n",
      "layers.7.1.weight\n",
      "False\n",
      "layers.7.1.bias\n",
      "False\n",
      "fc.weight\n",
      "True\n",
      "fc.bias\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for name, param in net_all1.named_parameters():\n",
    "    print(name)\n",
    "    print(param.requires_grad)\n",
    "#     if \"layers\" in name:\n",
    "#         param.requires_grad = False\n",
    "#     else:\n",
    "#         param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "dist_clusters = 1000\n",
    "splitting_dir = 'pc5'\n",
    "num_pts_cka = 10000\n",
    "\n",
    "data_per_classes, indexes = get_activations_by_class(train_act, train_labels)\n",
    "lin_sep, cka, split_embeds, indexes, split_indexes = test_cka_lin_sep(data_per_classes, indexes, lin_svc, num_clusters = 2, dist_clusters = 10000, splitting_dir = 'pc5', num_pts_cka = 10000, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of a linear SVM classifier on the original data: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/ai.mila.quebec/apps/x86_64/debian/anaconda/3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "train_activations, _ = net_all1.forward(train_data, all_act=True)\n",
    "train_act = train_activations[-1].reshape(train_activations[-1].shape[0],-1).detach().cpu().numpy()\n",
    "train_act_tensors = train_activations[-1]\n",
    "for i in train_activations[:-1]: del i\n",
    "del train_activations\n",
    "\n",
    "# Linear separability:\n",
    "lin_svc = LinearSVC()\n",
    "lin_svc.fit(train_act, train_labels)\n",
    "original_lin_sep = lin_svc.score(train_act, train_labels)\n",
    "print(\"Accuracy of a linear SVM classifier on the original data: {}\".format(original_lin_sep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check that the split does what it's supposed to and the indexes saved are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 2; Distance between clusters: 10000; Splitting direction: pc5; Number of points to compute CKA: 10000\n",
      "Accuracy of the linear SVM classifier on the split data: 0.9129\n",
      "Cka between 10000 original vs split pts: 0.3227207064628601\n"
     ]
    }
   ],
   "source": [
    "data_per_classes, indexes = get_activations_by_class(train_act, train_labels)\n",
    "lin_sep, cka, split_embeds, indexes, split_indexes = test_cka_lin_sep(data_per_classes, indexes, lin_svc, num_clusters = 2, dist_clusters = 10000, splitting_dir = 'pc5', num_pts_cka = 10000, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-af89278b7b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#     for j in i:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#         print(len(j))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#should be equl to 5000 (examples per class separated into two clusters)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlisst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_indexes\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "for i in split_indexes:\n",
    "#     for j in i:\n",
    "#         print(len(j))\n",
    "    print(len(i[0])+len(i[1])) #should be equl to 5000 (examples per class separated into two clusters)\n",
    "    \n",
    "lisst = [k for i in split_indexes for j in i for k in j]\n",
    "print(len(set(lisst))) # should be 50000\n",
    "lisst.sort\n",
    "print(sum(np.arange(50000)-np.array(lisst))) # should be equal to 0 (i.e. contains every element from 0 to 49999 included and only these)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "print(indexes[12])\n",
    "print(split_indexes[0][0][11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 64, 2, 2])\n",
      "torch.Size([50000, 64, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_act_tensors.shape)\n",
    "reshaped = train_act_tensors.reshape(train_act_tensors.shape[0],-1).reshape([50000,64,2,2])\n",
    "print(reshaped.shape)\n",
    "# print(train_act_tensors[0])\n",
    "# print(reshaped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "reshaped = train_act_tensors.reshape(train_act_tensors.shape[0],-1)\n",
    "reshaped = reshaped.reshape([reshaped.shape[0],64,2,2])\n",
    "\n",
    "differences = []\n",
    "differences1 = []\n",
    "for idx, i in enumerate(train_act_tensors):\n",
    "    differences.append(np.sum(i.detach().cpu().numpy()-reshaped[idx].detach().cpu().numpy()))\n",
    "    differences1.append(np.sum(i.detach().cpu().numpy()-i.reshape(256).reshape([64,2,2]).detach().cpu().numpy()))\n",
    "print(sum(differences))\n",
    "print(sum(differences1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape works in both directions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the index and the new points in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_val = transforms.Compose([transforms.ToTensor(), normalize]) \n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]) \n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "##### Cifar Data\n",
    "cifar_data = datasets.CIFAR10(root='.',train=True, transform=transform_train, download=True)\n",
    "cifar_data_test = datasets.CIFAR10(root='.',train=False, transform=transform_val, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Optional, Tuple\n",
    "class CIFAR10_mine(datasets.CIFAR10):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False) -> None:\n",
    "        super().__init__(root, transform=transform, target_transform=target_transform)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        a = super().__getitem__(index)\n",
    "        return (a[0], a[1], index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([transforms.ToTensor(), normalize]) \n",
    "\n",
    "cifar_data = CIFAR10_mine(root='.', train=True, download=True, transform = transform_val)\n",
    "train_loader = torch.utils.data.DataLoader(cifar_data, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,z in train_loader:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, R = np.linalg.qr(lin_svc.coef_.T)\n",
    "Q = Q.T\n",
    "\n",
    "direction = np.random.normal(0, 1, 256).T\n",
    "norm = np.sum(direction**2)**(0.5)\n",
    "direction = direction/norm\n",
    "direction = np.absolute(direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quadprog\n",
    "\n",
    "def quadprog_solve_qp(P, q, G=None, h=None, A=None, b=None):\n",
    "    qp_G = .5 * (P + P.T)   # make sure P is symmetric\n",
    "    qp_a = -q\n",
    "    if A is not None:\n",
    "        qp_C = -numpy.vstack([A, G]).T\n",
    "        qp_b = -numpy.hstack([b, h])\n",
    "        meq = A.shape[0]\n",
    "    else:  # no equality constraint\n",
    "        qp_C = -G.T\n",
    "        qp_b = -h\n",
    "        meq = 0\n",
    "    return quadprog.solve_qp(qp_G, qp_a, qp_C, qp_b, meq)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Q\n",
    "# P = np.dot(M.T, M) # Not positive definite\n",
    "epsilon = 0.00000001\n",
    "P = np.dot(M.T, M) + epsilon*np.eye(M.shape[1]) # Adding epsilon * identity to make it positive definite\n",
    "q = -np.dot(M.T, np.zeros(10))\n",
    "G = -np.eye(256)\n",
    "# h = np.zeros(256) # returns all zeros\n",
    "h =  -np.ones(256)*0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1        0.1        0.1        0.1        0.1        0.1395443\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.35295926 0.74807263 0.37181194 0.36263526\n",
      " 0.66555696 0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.14020782\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.34627948 0.53691978\n",
      " 0.66459626 0.53667065 0.37368035 0.8263061  0.31106512 0.1\n",
      " 0.1        0.38998344 0.26835046 0.24798285 0.1        0.1\n",
      " 0.1        0.1        0.25463257 0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.17849729 0.1        0.1\n",
      " 0.1        0.1        0.15660197 0.1        0.1        0.1\n",
      " 0.1        0.1        0.47445683 0.24342873 0.1        0.1\n",
      " 0.1        0.1        0.49283448 0.1        0.1        0.1\n",
      " 0.28920587 0.23837759 1.25208227 1.57400654 0.1        0.1\n",
      " 0.1        0.1        0.1587269  0.1        0.1        0.21494529\n",
      " 0.1        0.1        0.1        0.1        0.63647954 0.1\n",
      " 0.1        0.18427864 0.1        0.1        0.1        0.1\n",
      " 0.1        0.1160944  0.65459984 0.36784013 0.1        0.1\n",
      " 0.16153532 0.34702122 0.1        0.1        0.1        0.1\n",
      " 0.1        0.66725562 0.26126276 0.1        0.1        0.1\n",
      " 0.1        0.1        0.38411245 0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.12177971 0.1        0.2630327  0.11056885\n",
      " 0.50729501 0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.44318546 0.278665   0.1        0.52767191 0.36897107\n",
      " 0.11282302 0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.1        0.1        0.1        0.1        0.1        0.1\n",
      " 0.78517833 0.55871335 0.1        1.05139368 0.1        0.1\n",
      " 0.1        0.1        0.32597739 0.1        0.1        0.1\n",
      " 0.26337694 0.37379287 0.54797824 0.77113427 0.1        0.1\n",
      " 0.1        0.1        0.1818112  0.1        0.16190945 0.49675046\n",
      " 0.1        0.1        0.25645852 0.1       ]\n"
     ]
    }
   ],
   "source": [
    "sol = quadprog_solve_qp(P, q, G, h)\n",
    "print(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.41384983e-08,  4.41450581e-08,  4.58886932e-08,  5.13632785e-08,\n",
       "        3.53498133e-08,  4.62222439e-08,  4.05178575e-08, -3.73668767e-08,\n",
       "       -4.34134963e-08, -3.51095555e-08])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(M, sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons=[1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\n",
    "\n",
    "solutions = []\n",
    "values = []\n",
    "val_norms = []\n",
    "\n",
    "for index, epsilon in enumerate(epsilons):\n",
    "    M = Q\n",
    "    P = np.dot(M.T, M) + epsilon*np.eye(M.shape[1]) # Adding epsilon * identity to make it positive definite\n",
    "    q = -np.dot(M.T, np.zeros(10))\n",
    "    G = -np.eye(256)\n",
    "    h =  -np.ones(256)*0.1\n",
    "\n",
    "    solutions.append(quadprog_solve_qp(P, q, G, h))\n",
    "    values.append(np.dot(M, solutions[-1]))\n",
    "    val_norms.append(np.linalg.norm(values[-1]))\n",
    "\n",
    "sol_norms = [np.linalg.norm(solutions[i]-solutions[-1]) for i in range(len(solutions))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilons, sol_norms)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "# Almost linear relation betwen value of epsilon and how far the solution is from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epsilons, sol_norms)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sd' in 'fdsasd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Basic_CKA_ForSharing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (main_env)",
   "language": "python",
   "name": "main_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "522e0f024813495bb45905626fdccd14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8de220001a4c42e6b2bf369d63e17658",
       "IPY_MODEL_9a5b5204bd3847d485f8a139949a79f4",
       "IPY_MODEL_b0283df5d40143789293e11c9428d543"
      ],
      "layout": "IPY_MODEL_916a6726fe5b4b8a949d1d6b1d4bfec1"
     }
    },
    "6d746b9790c744ac91ff6c7cc852f9f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70d14a62a0e94362bea840e44b5719e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "890787b726f4485199dcb2a059ef92a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8de220001a4c42e6b2bf369d63e17658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d746b9790c744ac91ff6c7cc852f9f7",
      "placeholder": "​",
      "style": "IPY_MODEL_ad439d60a52447469bcdce66a8e3c0bd",
      "value": ""
     }
    },
    "8ec5fa1d3675438ba3e5097f6f605325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "916a6726fe5b4b8a949d1d6b1d4bfec1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a5b5204bd3847d485f8a139949a79f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e34af8bd1fe3408cbd99341d4271f845",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_890787b726f4485199dcb2a059ef92a3",
      "value": 170498071
     }
    },
    "ad439d60a52447469bcdce66a8e3c0bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0283df5d40143789293e11c9428d543": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70d14a62a0e94362bea840e44b5719e3",
      "placeholder": "​",
      "style": "IPY_MODEL_8ec5fa1d3675438ba3e5097f6f605325",
      "value": " 170499072/? [00:05&lt;00:00, 32259211.76it/s]"
     }
    },
    "e34af8bd1fe3408cbd99341d4271f845": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
